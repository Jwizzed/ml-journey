{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7447509,"sourceType":"datasetVersion","datasetId":4334995},{"sourceId":7392775,"sourceType":"datasetVersion","datasetId":4297782}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Tools","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport gc\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import vit_b_16, ViT_B_16_Weights\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nimport pytorch_lightning as pl\nimport albumentations as albu\nfrom sklearn.model_selection import KFold, GroupKFold\nimport torchvision.transforms as transforms\nimport random","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    seed = 42 \n    image_transform = transforms.Resize((512,512))  \n    batch_size = 16\n    num_epochs = 20\n    num_folds = 5\n#     root_path = \"\"\n    spec_path = \"/kaggle/input/brain-spectrograms/specs.npy/\"\n    egg_path = \"/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy/\"\n    root_path = \"/kaggle/input/hms-harmful-brain-activity-classification/\"\n\ndef set_seed(seed):\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    torch.set_float32_matmul_precision('medium')\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nset_seed(Config.seed)\n\ndef KL_loss(p,q):\n    epsilon=10**(-15)\n    p=torch.clip(p,epsilon,1-epsilon)\n    q = nn.functional.log_softmax(q,dim=1)\n    return torch.mean(torch.sum(p*(torch.log(p)-q),dim=1))\n\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get a data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(Config.root_path + 'train.csv')\nTARGETS = df.columns[-6:]\nprint('Train shape:', df.shape )\nprint('Targets', list(TARGETS))\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df.groupby('eeg_id')[\n    ['spectrogram_id', 'spectrogram_label_offset_seconds']\n].agg({'spectrogram_id': 'first', 'spectrogram_label_offset_seconds': 'min'})\ntrain.columns = ['spec_id', 'min']\n\ntmp = df.groupby('eeg_id')[\n    ['spectrogram_id','spectrogram_label_offset_seconds']\n].agg({'spectrogram_label_offset_seconds' :'max'})\ntrain['max'] = tmp\n\ntmp = df.groupby('eeg_id')[['patient_id']].agg('first')\ntrain['patient_id'] = tmp\n\ntmp = df.groupby('eeg_id')[TARGETS].agg('sum')\nfor t in TARGETS:\n    train[t] = tmp[t].values\n    \ny_data = train[TARGETS].values\ny_data = y_data / y_data.sum(axis=1, keepdims=True)\ntrain[TARGETS] = y_data\n\ntmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')\ntrain['target'] = tmp\n\ntrain = train.reset_index()\nprint('Train non-overlapp eeg_id shape:', train.shape )\ntrain.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spectrograms = np.load(Config.spec_path + 'specs.npy',allow_pickle=True).item()\nall_eegs = np.load(Config.egg_path + 'eeg_specs.npy',allow_pickle=True).item()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"TARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\nTARS2 = {x: y for y, x in TARS.items()}\n\n\nclass ViTDataset(Dataset):\n    \n    def __init__(self, data, augment=False, mode='train', specs=spectrograms, eeg_specs=all_eegs): \n        self.data = data\n        self.augment = augment\n        self.mode = mode\n        self.specs = specs\n        self.eeg_specs = eeg_specs\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        return self.__getitems__([index])\n    \n    def __getitems__(self, indices):\n        X, y = self._generate_data(indices)\n        if self.augment:\n            X = self._augment(X) \n        if self.mode == 'train':\n            return list(zip(X, y))\n        else:\n            return X\n    \n    def _generate_data(self, indexes):\n        X = np.zeros((len(indexes), 128, 256, 8),dtype='float32')\n        y = np.zeros((len(indexes), 6),dtype='float32')\n        img = np.ones((128, 256),dtype='float32')\n        \n        for j, i in enumerate(indexes):\n            row = self.data.iloc[i]\n            if self.mode == 'test': \n                r = 0\n            else: \n                r = int((row['min'] + row['max'])//4)\n\n            for k in range(4):\n                # EXTRACT 300 ROWS OF SPECTROGRAM\n                img = self.specs[row.spec_id][r:r+300, k*100:(k+1)*100].T\n                \n                # LOG TRANSFORM SPECTROGRAM\n                img = np.clip(img, np.exp(-4), np.exp(8))\n                img = np.log(img)\n                \n                # STANDARDIZE PER IMAGE\n                ep = 1e-6\n                m = np.nanmean(img.flatten())\n                s = np.nanstd(img.flatten())\n                img = (img - m) / (s + ep)\n                img = np.nan_to_num(img, nan=0.0)\n                \n                # CROP TO 256 TIME STEPS\n                X[j, 14:-14, :, k] = img[:, 22:-22] / 2.0\n        \n            # EEG SPECTROGRAMS\n            img = self.eeg_specs[row.eeg_id]\n            X[j, :, :, 4:] = img\n                \n            if self.mode != 'test':\n                y[j,] = row[TARGETS]\n            \n        return X, y\n    \n    def _random_transform(self, img):\n        composition = albu.Compose([\n            albu.HorizontalFlip(p=0.5),\n            # albu.CoarseDropout(max_holes=8,max_height=32,max_width=32,fill_value=0,p=0.5),\n        ])\n        return composition(image=img)['image']\n            \n    def __augment(self, img_batch):\n        for i in range(img_batch.shape[0]):\n            img_batch[i,] = self._random_transform(img_batch[i,])\n        return img_batch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"class ViT(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n        self.base_model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n        num_features = self.base_model.head.in_features\n        self.base_model.head = nn.Linear(num_features, 6)\n        self.prob_out = nn.Softmax()\n        \n    def forward(self, x):\n        x1 = [x[:, :, :, i:i+1] for i in range(4)]\n        x1 = torch.concat(x1, dim=1)\n        x2 = [x[:, :, :, i+4:i+5] for i in range(4)]\n        x2 = torch.concat(x2, dim=1)\n        \n        x = torch.concat([x1, x2], dim=2)\n\n        x = torch.concat([x, x, x], dim=3)\n        x = x.permute(0, 3, 1, 2)\n        \n        out = self.base_model(x)\n        return out\n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        out = self.forward(x)\n        out = F.log_softmax(out, dim=1)\n        kl_loss = nn.KLDivLoss(reduction='batchmean')\n        loss = kl_loss(out, y)\n        return loss\n    \n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        return F.softmax(self(batch), dim=1)\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Find best params","metadata":{}},{"cell_type":"code","source":"# import optuna\n# from pytorch_lightning import Trainer\n\n# def objective(trial):\n#     lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n#     batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n    \n#     train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=3, persistent_workers=True)\n#     model = EEGEffnetB0(lr=lr)\n\n#     trainer = Trainer(\n#         max_epochs=10,\n#         gpus=1 if torch.cuda.is_available() else 0,\n#     )\n    \n#     trainer.fit(model, train_loader, valid_loader)\n#     return trainer.callback_metrics[\"val_loss\"].item()\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials=10)\n# print(\"Best trial:\", study.best_trial.params)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"all_oof = []\nall_true = []\nvalid_loaders = []\n\ngkf = GroupKFold(n_splits=5)\nfor i, (train_index, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):  \n    print('#'*25)\n    print(f'### Fold {i+1}')\n    \n    train_ds = Dataset(train.iloc[train_index])\n    train_loader = DataLoader(train_ds, shuffle=True, batch_size=32, num_workers=3, persistent_workers=True)\n    valid_ds = EEGDataset(train.iloc[valid_index], mode='valid')\n    valid_loader = DataLoader(valid_ds, shuffle=False, batch_size=64, num_workers=3)\n    \n    print(f'### Train size: {len(train_index)}, Valid size: {len(valid_index)}')\n    print('#'*25)\n    \n    trainer = pl.Trainer(max_epochs=4)\n    model = EEGEffnetB7()\n    trainer.fit(model=model, train_dataloaders=train_loader)\n    trainer.save_checkpoint(f'Vit_f{i}.ckpt')\n\n    valid_loaders.append(valid_loader)\n    all_true.append(train.iloc[valid_index][TARGETS].values)\n    del trainer, model\n    gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    print('#'*25)\n    print(f'### Validating Fold {i+1}')\n\n    ckpt_file = f'Vit_f{i}.pth'\n    model = EEGEffnetB0.load_from_checkpoint(ckpt_file)\n    model.to(device).eval()\n    with torch.inference_mode():\n        for val_batch in valid_loaders[i]:\n            val_batch = val_batch.to(device)\n            oof = torch.softmax(model(val_batch), dim=1).cpu().numpy()\n            all_oof.append(oof)\n    del model\n    gc.collect()\n\nall_oof = np.concatenate(all_oof)\nall_true = np.concatenate(all_true)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = pd.DataFrame(all_oof.copy())\noof['id'] = np.arange(len(oof))\n\ntrue = pd.DataFrame(all_true.copy())\ntrue['id'] = np.arange(len(true))\n\n# cv = score(solution=true, submission=oof, row_id_column_name='id')\nkl_loss = nn.KLDivLoss(reduction='batchmean')\nloss = kl_loss(out, y)\nprint('CV Score KL-Div for EfficientNetB0 =', loss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del all_eegs, spectrograms\ngc.collect()\n\ntest = pd.read_csv(Config.root_path + 'test.csv')\nprint('Test shape',test.shape)\ntest.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH2 = Config.root_path + 'test_spectrograms/'\nfiles2 = os.listdir(PATH2)\nprint(f'There are {len(files2)} test spectrogram parquets')\n    \nspectrograms2 = {}\nfor i, f in enumerate(files2):\n    if i % 100 == 0:\n        print(i, ', ',end='')\n    tmp = pd.read_parquet(f'{PATH2}{f}')\n    name = int(f.split('.')[0])\n    spectrograms2[name] = tmp.iloc[:, 1:].values\n    \n# RENAME FOR DATALOADER\ntest = test.rename({'spectrogram_id': 'spec_id'}, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INFER EFFICIENTNET ON TEST\npreds = []\ntest_ds = EEGDataset(test, mode='test', specs=spectrograms2, eeg_specs=all_eegs2)\ntest_loader = DataLoader(test_ds, shuffle=False, batch_size=64, num_workers=3)\n\nfor i in range(5):\n    print('#'*25)\n    print(f'### Testing Fold {i+1}')\n\n    ckpt_file = f'EffNet_f{i}.ckpt'\n    model = EEGEffnetB0.load_from_checkpoint(ckpt_file)\n    model.to(device).eval()\n    fold_preds = []\n\n    with torch.inference_mode():\n        for test_batch in test_loader:\n            test_batch = test_batch.to(device)\n            pred = torch.softmax(model(test_batch), dim=1).cpu().numpy()\n            fold_preds.append(pred)\n        fold_preds = np.concatenate(fold_preds)\n\n    preds.append(fold_preds)\n\npred = np.mean(preds,axis=0)\nprint()\nprint('Test preds shape',pred.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame({'eeg_id': test.eeg_id.values})\nsub[TARGETS] = pred\nsub.to_csv('submission.csv',index=False)\nprint('Submissionn shape',sub.shape)\nsub.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.iloc[:,-6:].sum(axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}